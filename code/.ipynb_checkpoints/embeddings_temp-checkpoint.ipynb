{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def tsnescatterplot(model, word, list_names, color_list):\n",
    "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\n",
    "    \"\"\"\n",
    "    arrays = np.empty((0, 50), dtype='f')\n",
    "    word_labels = [word]\n",
    "    #color_list  = ['red']\n",
    "\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "    \n",
    "    # gets list of most similar words\n",
    "    close_words = model.wv.most_similar([word])\n",
    "    \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        #color_list.append('blue')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.__getitem__([wrd])\n",
    "        word_labels.append(wrd)\n",
    "        #color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "        \n",
    "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "    reduc = PCA(n_components=15).fit_transform(arrays)\n",
    "    \n",
    "    # Finds t-SNE coordinates for 2 dimensions\n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
    "    \n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words': word_labels,\n",
    "                       'color': color_list})\n",
    "    \n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    \n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df['color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "         p1.text(df[\"x\"][line],\n",
    "                 df['y'][line],\n",
    "                 '  ' + df[\"words\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df['color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    "\n",
    "    \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "            \n",
    "    plt.title('t-SNE visualization for {}'.format(word.title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb15b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_db_rows():\n",
    "    # Named cursor => server side cursor. Without this, _all_ data from the\n",
    "    # query will be fetched into memory, which defeats the purpose of streaming\n",
    "    query=\"SELECT codes FROM concept_embeddings.codes_by_site_pasc_78\"\n",
    "    with \\\n",
    "            psycopg2.connect(user=\"lormanv\",\n",
    "                                  password=\"\",\n",
    "                                  host=\"reslnpedsndb06.research.chop.edu\",\n",
    "                                  port=\"5432\",\n",
    "                                  database=\"dcc_covid_wk124_220818\") as conn, \\\n",
    "            conn.cursor(name='get_rows') as cur:\n",
    "        cur.itersize = 5\n",
    "        cur.arraysize = 5\n",
    "        cur.execute(query)\n",
    "\n",
    "        while True:\n",
    "            rows_temp = cur.fetchmany()\n",
    "            rows=[x[0].split(\" \") for x in rows_temp]     \n",
    "#            rows=[list(set(x)) for x in rows_temp2]\n",
    "            for row in rows:\n",
    "#                if (len(row)>1):\n",
    "                    yield random.sample(row, len(row))\n",
    "            if not rows:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesIterator():\n",
    "    def __init__(self, generator_function):\n",
    "        self.generator_function = generator_function\n",
    "        self.generator = self.generator_function()\n",
    "\n",
    "    def __iter__(self):\n",
    "        # reset the generator\n",
    "        self.generator = self.generator_function()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        result = next(self.generator)\n",
    "        if result is None:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = SentencesIterator(fetch_db_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d6cf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(vector_size=200, window=5, min_count=3, workers=12, sg=1, hs=1, negative=5)\n",
    "#model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55e2bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.build_vocab(sentences, progress_per=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68339e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('./model_all_sites_full')\n",
    "#new_model = gensim.models.Word2Vec.load('./tmp/mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = SentencesIterator(fetch_db_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bbfca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(sentences,total_examples=model.corpus_count, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_all_sites_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class LossLogger(CallbackAny2Vec):\n",
    "    '''Output loss at each epoch'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f'Epoch: {self.epoch}', end='\\t')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        self.losses.append(loss)\n",
    "        print(f'  Loss: {loss}')\n",
    "        self.epoch += 1\n",
    "\n",
    "loss_logger = LossLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sentences,total_examples=model.corpus_count, epochs=15, callbacks=[loss_logger],\n",
    "                                      compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec.load('./mymodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
